{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert natural language voice into a SPARQL query using Python, you need to integrate various components, including speech recognition, natural language understanding, and query generation. Here's a detailed step-by-step guide with example codes for each stage:\n",
    "\n",
    "Step 1: Speech Recognition\n",
    "Start by transcribing the spoken words into text using speech recognition. The SpeechRecognition library is commonly used for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak:\n",
      "You said: the properties about Apollo 7\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak:\")\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"You said:\", text)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech recognition could not understand audio.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from speech recognition service; {0}\".format(e))\n",
    "\n",
    "# Call the function to get the recognized text\n",
    "recognized_text = recognize_speech()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Natural Language Understanding (NLU)\n",
    "Perform natural language understanding to extract intent and entities from the recognized text. Libraries like spaCy or NLTK can be used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def extract_intent_entities(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract intent\n",
    "    intent = None\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            intent = token.lemma_\n",
    "            break\n",
    "    \n",
    "    # Extract entities\n",
    "    entities = []\n",
    "    for entity in doc.ents:\n",
    "        entities.append((entity.text, entity.label_))\n",
    "    \n",
    "    return intent, entities\n",
    "\n",
    "# Call the function to extract intent and entities\n",
    "intent, entities = extract_intent_entities(recognized_text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Query Generation\n",
    "Based on the extracted intent and entities, generate a SPARQL query. Define query templates and fill in the entities as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sparql_query(intent, entities):\n",
    "    if intent == \"find\":\n",
    "        # Query template for finding information\n",
    "        entity = None\n",
    "        for ent_text, ent_type in entities:\n",
    "            if ent_type == \"PERSON\" or ent_type == \"ORG\":\n",
    "                entity = ent_text\n",
    "                break\n",
    "        if entity:\n",
    "            sparql_query = f\"SELECT ?property ?value WHERE {{ <{entity}> ?property ?value }}\"\n",
    "        else:\n",
    "            sparql_query = \"No entity found for the query.\"\n",
    "    elif intent == \"count\":\n",
    "        # Query template for counting entities\n",
    "        entity_type = None\n",
    "        for ent_text, ent_type in entities:\n",
    "            if ent_type == \"PERSON\" or ent_type == \"ORG\":\n",
    "                entity_type = ent_type.lower()\n",
    "                break\n",
    "        if entity_type:\n",
    "            sparql_query = f\"SELECT (COUNT(?entity) AS ?count) WHERE {{ ?entity rdf:type dbpedia:{entity_type} }}\"\n",
    "        else:\n",
    "            sparql_query = \"No entity type found for the query.\"\n",
    "    else:\n",
    "        sparql_query = \"Intent not supported for the query.\"\n",
    "\n",
    "    return sparql_query\n",
    "\n",
    "# Call the function to generate the SPARQL query\n",
    "sparql_query = generate_sparql_query(intent, entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql_query = generate_sparql_query(intent, entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Intent not supported for the query.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparql_query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3212650815.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    return text\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import spacy\n",
    "\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak:\")\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"You said:\", text)\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "while True:\n",
    "    url0 = \"https://thingsboard.cs.cf.ac.uk/api/auth/login\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    payload = {\n",
    "        \"username\": \"SuhasAbacwsLivingLab@cardiff.ac.uk\",\n",
    "        \"password\": \"SuhasDevmane\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url0, json=payload, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Authentication successful\n",
    "        token = response.json().get(\"token\")\n",
    "        print(\"JWT_Token:\", token)\n",
    "    else:\n",
    "        print(\"Authentication failed. Status Code:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "\n",
    "    access_token = token  \n",
    "    keys_to_fetch = [\n",
    "        \"UV_light\", \"Loudness\", \"PM1.0Atmospheric\", \"PM2.5Atmospheric\", \"PM10Atmospheric\", \n",
    "        \"PIR_Status\", \"tVOC_Concentration\", \"CO2eq_Concentration\", \"MQ2_sensor_voltage\", \n",
    "        \"MQ2_Rs_ratio\", \"MQ2_Rs/R0_Ratio\", \"MQ3_sensor_voltage\", \"MQ3_Rs_ratio\", \n",
    "        \"MQ3_Rs/R0_Ratio\", \"HCHO_ppm\", \"Air_Quality\", \"Light_value\", \"Visible_light\", \n",
    "        \"IR_light\", \"MQ5_sensor_voltage\", \"MQ5_Rs_ratio\", \"MQ5_Rs/R0_Ratio\", \n",
    "        \"MQ9_sensor_voltage\", \"MQ9_Rs_ratio\", \"MQ9_Rs/R0_Ratio\", \"O2_22.10_N2_gas\", \n",
    "        \"C2H5CH_gas\", \"VOC_gas\", \"CO_gas\", \"Co2\", \"Temperature\", \"Humidity\", \"Luminance\"\n",
    "    ]\n",
    "\n",
    "    units = {\n",
    "        \"UV_light\": \"UV Index\",\n",
    "        \"Loudness\": \"dB\",\n",
    "        \"PM1.0Atmospheric\": \"µg/m³\",\n",
    "        \"PM2.5Atmospheric\": \"µg/m³\",\n",
    "        \"PM10Atmospheric\": \"µg/m³\",\n",
    "        \"PIR_Status\": \"\",  # Assuming it's a status indicator with no specific unit\n",
    "        \"tVOC_Concentration\": \"ppb\",\n",
    "        \"CO2eq_Concentration\": \"ppm\",\n",
    "        \"MQ2_sensor_voltage\": \"Volts\",\n",
    "        \"MQ2_Rs_ratio\": \"\",\n",
    "        \"MQ2_Rs/R0_Ratio\": \"\",\n",
    "        \"MQ3_sensor_voltage\": \"Volts\",\n",
    "        \"MQ3_Rs_ratio\": \"\",\n",
    "        \"MQ3_Rs/R0_Ratio\": \"\",\n",
    "        \"HCHO_ppm\": \"ppm\",\n",
    "        \"Air_Quality\": \"\",  # Assuming it's a qualitative measure with no specific unit\n",
    "        \"Light_value\": \"Lux\",\n",
    "        \"Visible_light\": \"Lux\",\n",
    "        \"IR_light\": \"Lux\",\n",
    "        \"MQ5_sensor_voltage\": \"Volts\",\n",
    "        \"MQ5_Rs_ratio\": \"\",\n",
    "        \"MQ5_Rs/R0_Ratio\": \"\",\n",
    "        \"MQ9_sensor_voltage\": \"Volts\",\n",
    "        \"MQ9_Rs_ratio\": \"\",\n",
    "        \"MQ9_Rs/R0_Ratio\": \"\",\n",
    "        \"O2_22.10_N2_gas\": \"\",  # Assuming it's a gas measurement with no specific unit\n",
    "        \"C2H5CH_gas\": \"\",  # Assuming it's a gas measurement with no specific unit\n",
    "        \"VOC_gas\": \"\",  # Assuming it's a gas measurement with no specific unit\n",
    "        \"CO_gas\": \"\",  # Assuming it's a gas measurement with no specific unit\n",
    "        \"Co2\": \"\",  # Assuming it's a gas measurement with no specific unit\n",
    "        \"Temperature\": \"°C\",\n",
    "        \"Humidity\": \"%\",\n",
    "        \"Luminance\": \"cd/m²\"\n",
    "    }\n",
    "\n",
    "    pairs = [\n",
    "            ('70ad22a0-b82c-11ed-b196-bb47e24272bc','node_5.01'),\n",
    "            ('75d29440-b82c-11ed-b196-bb47e24272bc','node_5.02'),\n",
    "            ('7b717ba0-b82c-11ed-b196-bb47e24272bc','node_5.03'),\n",
    "            ('a673eb80-b82c-11ed-b196-bb47e24272bc','node_5.04'),\n",
    "            ('83456b70-b82c-11ed-b196-bb47e24272bc','node_5.05'),\n",
    "            ('b96d6720-b82c-11ed-b196-bb47e24272bc','node_5.06'),\n",
    "            ('be98a520-b82c-11ed-b196-bb47e24272bc','node_5.07'),\n",
    "            ('c3110de0-b82c-11ed-b196-bb47e24272bc','node_5.08'),\n",
    "            ('c950f030-b82c-11ed-b196-bb47e24272bc','node_5.09'),\n",
    "            ('cfddba00-b82c-11ed-b196-bb47e24272bc','node_5.10'),\n",
    "            ('278505c0-0f7a-11ee-bf90-a16a1a9e1e0a','node_5.11'),\n",
    "            ('d9576a90-b82c-11ed-b196-bb47e24272bc','node_5.12'),\n",
    "            ('de18ea40-b82c-11ed-b196-bb47e24272bc','node_5.13'),\n",
    "            ('f57a1560-7cf3-11ee-94bc-d389020903a3','node_5.14'),\n",
    "            ('508d1b60-57eb-11ee-8714-19d56ba0c4fd','node_5.15'),\n",
    "            ('86c63bd0-57f0-11ee-8714-19d56ba0c4fd','node_5.16'),\n",
    "            ('3efd82d0-7cf4-11ee-94bc-d389020903a3','node_5.17'),\n",
    "            ('f583bc50-57e6-11ee-8714-19d56ba0c4fd','node_5.18'),\n",
    "            ('9458c560-0f75-11ee-bf90-a16a1a9e1e0a','node_5.19'),\n",
    "            ('cbc851c0-57ee-11ee-8714-19d56ba0c4fd','node_5.20'),\n",
    "            ('2ae959b0-53c6-11ee-8714-19d56ba0c4fd','node_5.21'),\n",
    "            ('351b0eb0-57ef-11ee-8714-19d56ba0c4fd','node_5.22'),\n",
    "            ('0f96bed0-b82d-11ed-b196-bb47e24272bc','node_5.23'),\n",
    "            ('13e642d0-b82d-11ed-b196-bb47e24272bc','node_5.24'),\n",
    "            ('18a159e0-b82d-11ed-b196-bb47e24272bc','node_5.25'),\n",
    "            ('fef50770-57f1-11ee-8714-19d56ba0c4fd','node_5.26'),\n",
    "            ('2a5d9a90-b82d-11ed-b196-bb47e24272bc','node_5.27'),\n",
    "            ('99c6a3b0-b82b-11ed-b196-bb47e24272bc','node_5.28'),\n",
    "            ('51f2d170-57e1-11ee-8714-19d56ba0c4fd','node_5.29'),\n",
    "            ('9c563630-0f75-11ee-bf90-a16a1a9e1e0a','node_5.30'),\n",
    "            ('391303e0-b82d-11ed-b196-bb47e24272bc','node_5.31'),\n",
    "            ('3d3a3f60-b82d-11ed-b196-bb47e24272bc','node_5.32'),\n",
    "            ('a83a46c0-7cf4-11ee-94bc-d389020903a3','node_5.33'),\n",
    "            ('4665a8e0-b82d-11ed-b196-bb47e24272bc','node_5.34')\n",
    "        \n",
    "    ]\n",
    "\n",
    "    # Keep track of the last received timestamp\n",
    "    last_ts = None\n",
    "\n",
    "    # Run the code for each pair\n",
    "    for device_id, node_name in pairs:\n",
    "        url1 = f\"https://thingsboard.cs.cf.ac.uk/api/plugins/telemetry/DEVICE/{device_id}/values/timeseries?keys={','.join(keys_to_fetch)}\"\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'X-Authorization': f'Bearer {access_token}'\n",
    "        }\n",
    "\n",
    "        response = requests.get(url1, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            # Remove the extra brackets and format the data\n",
    "            formatted_data = {}\n",
    "            for key in data:\n",
    "                if key in units:\n",
    "                    try:\n",
    "                        value = float(data[key][0][\"value\"])\n",
    "                    except ValueError:\n",
    "                        value = data[key][0][\"value\"]  # If not numeric, keep the original value\n",
    "\n",
    "                    formatted_data[key.lower()] = {\n",
    "                        \"value\": value,\n",
    "                        \"units\": units[key]\n",
    "                    }\n",
    "\n",
    "            # Check if the current timestamp is different from the last one\n",
    "            current_ts = data[key][0][\"ts\"]\n",
    "            if current_ts != last_ts:\n",
    "                print(f\"Received data for {device_id}:{node_name}:\")\n",
    "                print(json.dumps(formatted_data, indent=2))\n",
    "\n",
    "                # ... (your code for sending data)\n",
    "\n",
    "                try:\n",
    "                    # time.sleep(1)\n",
    "                    url2 = f'http://visualiser:80/api/devices/{node_name}/data'\n",
    "                    response = requests.put(url2, headers=headers, data=json.dumps(formatted_data))\n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        json_data = response.json()\n",
    "                        # Process the JSON data as needed\n",
    "                        print(json_data)\n",
    "\n",
    "                        # Update the last timestamp\n",
    "                        last_ts = current_ts\n",
    "                    else:\n",
    "                        print(f\"Error: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"Request error: {e}\")\n",
    "            else:\n",
    "                print(f\"Received data with the same timestamp for {device_id}:{node_name}. Skipping...\")\n",
    "        else:\n",
    "            print(f\"Failed to get data for {device_id}:{node_name}. Status Code: {response.status_code}\")\n",
    "            print(response.text)\n",
    "    time.sleep(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

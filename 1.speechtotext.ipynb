{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1. VOICE/AUDIO TO TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert spoken words into text using automatic speech recognition (ASR) technology in Python, you can use the SpeechRecognition library. Here's an example code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code: 200\n",
      "{\"K1\":[{\"ts\":1689413673035,\"value\":\"27.01\"}]}\n",
      "27.01\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://thingsboard.cs.cf.ac.uk/api/plugins/telemetry/DEVICE/9c563630-0f75-11ee-bf90-a16a1a9e1e0a/values/timeseries?keys=K1\"\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Authorization': 'Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJTdWhhc0FiYWN3c0xpdmluZ0xhYkBjYXJkaWZmLmFjLnVrIiwic2NvcGVzIjpbIlRFTkFOVF9BRE1JTiJdLCJ1c2VySWQiOiIzNTg1MzkzMC1kYjc2LTExZWMtOTY0NC0zZDY2MDFiMTlmMmMiLCJmaXJzdE5hbWUiOiJTdWhhcyIsImxhc3ROYW1lIjoiRGV2bWFuZSIsImVuYWJsZWQiOnRydWUsImlzUHVibGljIjpmYWxzZSwidGVuYW50SWQiOiJmOTFlNDU5MC1kYjc1LTExZWMtOTY0NC0zZDY2MDFiMTlmMmMiLCJjdXN0b21lcklkIjoiMTM4MTQwMDAtMWRkMi0xMWIyLTgwODAtODA4MDgwODA4MDgwIiwiaXNzIjoidGhpbmdzYm9hcmQuaW8iLCJpYXQiOjE2OTExNjYyMTIsImV4cCI6MTY5MTE3NTIxMn0.Q-YFgoaZzToeXs9NN20Hn2HUFPCgp8HTI2e9dDfTsLu3lvvWcbfk2DaCzlB3nGEQOS2BZ25DUGFEwERfVNCmHQ'\n",
    "\n",
    "}\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "print('status code:',response.status_code)\n",
    "print(response.text)\n",
    "value = json.loads(response.text)[\"K1\"][0][\"value\"]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.01\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = json.loads(response.text)\n",
    "value = data[\"K1\"][0][\"value\"]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.01\n"
     ]
    }
   ],
   "source": [
    "value = json.loads(response.text)[\"K1\"][0][\"value\"]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognized text: can you please make some tea for me\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sre\n",
    "\n",
    "# Create a recognizer instance\n",
    "recognizer = sre.Recognizer()\n",
    "\n",
    "# Specify the audio source (e.g., microphone)\n",
    "with sre.Microphone() as source:\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    # Adjust for ambient noise levels\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "    # Capture the audio input from the microphone\n",
    "    audio = recognizer.listen(source)\n",
    "\n",
    "# Perform speech recognition\n",
    "try:\n",
    "    # Use Google Web Speech API for recognition\n",
    "    text = recognizer.recognize_google(audio)\n",
    "    print(\"Recognized text:\", text)\n",
    "except sre.UnknownValueError:\n",
    "    print(\"Speech recognition could not understand audio.\")\n",
    "except sre.RequestError as e:\n",
    "    print(\"Error occurred in the speech recognition service:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you please make some tea for me\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code snippet above, we first create a recognizer instance using sr.Recognizer(). Then, we specify the audio source as the microphone using sr.Microphone(). Within the with block, we capture the audio input from the microphone.\n",
    "\n",
    "Before performing speech recognition, it is recommended to adjust for ambient noise levels using recognizer.adjust_for_ambient_noise(source) to account for any background noise. Then, we use the recognize_google() method to perform speech recognition using the Google Web Speech API. Finally, the recognized text is printed to the console.\n",
    "\n",
    "Ensure that you have installed the SpeechRecognition library using pip install SpeechRecognition before running the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio file to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the Audio Source: Determine the audio source for speech recognition. This can be a microphone input, an audio file, or a streaming audio source. Here are examples for microphone input and audio file input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \"recordings/recording.wav\"\n",
    "with sr.AudioFile(audio_file) as source:\n",
    "    audio = recognizer.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # text = recognizer.recognize_sphinx(audio)  # Using Sphinx engine\n",
    "    # or\n",
    "    text = recognizer.recognize_google(audio)  # Using Google Web Speech API\n",
    "    # Process the recognized text...\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Edinburgh because well lots of buses and planes go high good place and I went to the eye boggling thing'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose different speech recognition engines depending on your requirements and available options. The example above shows the use of the Sphinx engine (offline) and the Google Web Speech API (online). You may need to install additional dependencies or set up API credentials for online engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the Recognized Text: Once the speech recognition process is complete, you can work with the recognized text as needed. You can perform further analysis, extract relevant information, or use it to generate a SPARQL query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that speech recognition accuracy can vary based on factors such as audio quality, background noise, and the specific speech recognition engine being used. It may require some experimentation and adjustment to achieve optimal results for your specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2. TEXT PROCESSING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the recognized text involves working with the output of the speech recognition step, which is the transcribed text obtained from the audio input. In Python, once you have the recognized text, you can perform various operations on it based on your specific requirements. Here are a few examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Natural Language Understanding (NLU)/ Text Analysis : \n",
    "Perform natural language understanding to extract intent and entities from the recognized text. Libraries like spaCy or NLTK can be used for this purpose. You can use libraries such to perform tasks like part-of-speech tagging, named entity recognition, sentiment analysis, or topic extraction. These analyses can provide valuable insights and help you understand the content and context of the speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Edinburgh because well lots of buses and planes go high good place and I went to the eye boggling thing'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intent_entities(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract intent\n",
    "    intent = None\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            intent = token.lemma_\n",
    "            break\n",
    "    \n",
    "    # Extract entities\n",
    "    entities = []\n",
    "    for entity in doc.ents:\n",
    "        entities.append((entity.text, entity.label_))\n",
    "    \n",
    "    return intent, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"List the designated safe areas for shelter during extreme weather events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to extract intent and entities\n",
    "intent, entities = extract_intent_entities(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('list', [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\c21054458\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\c21054458\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\c21054458\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "\n",
    "recognized_text = 'Edinburgh because well lots of buses and planes go high good place and I went to the eye boggling thing'\n",
    "\n",
    "# Tokenize the recognized text into sentences and words\n",
    "sentences = sent_tokenize(recognized_text)\n",
    "words = word_tokenize(recognized_text)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "# Perform named entity recognition\n",
    "named_entities = ne_chunk(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,1016.0,168.0\" width=\"1016px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"8.66142%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Edinburgh</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.33071%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.08661%\" x=\"8.66142%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">because</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">RB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.2047%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.72441%\" x=\"15.748%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">well</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">RB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1102%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.72441%\" x=\"20.4724%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">lots</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.8346%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.14961%\" x=\"25.1969%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.7717%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.51181%\" x=\"28.3465%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">buses</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.1024%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.93701%\" x=\"33.8583%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35.8268%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6.29921%\" x=\"37.7953%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">planes</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.9449%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.93701%\" x=\"44.0945%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">go</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.063%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.72441%\" x=\"48.0315%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">high</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50.3937%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.72441%\" x=\"52.7559%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">good</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.1181%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.51181%\" x=\"57.4803%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">place</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"60.2362%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.93701%\" x=\"62.9921%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.9606%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.93701%\" x=\"66.9291%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">I</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.8976%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.72441%\" x=\"70.8661%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">went</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.2283%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.14961%\" x=\"75.5906%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">to</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">TO</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.1654%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.93701%\" x=\"78.7402%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80.7087%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.93701%\" x=\"82.6772%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">eye</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.6457%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.87402%\" x=\"86.6142%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">boggling</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.5512%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.51181%\" x=\"94.4882%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">thing</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.2441%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Edinburgh', 'NNP')]), ('because', 'RB'), ('well', 'RB'), ('lots', 'NNS'), ('of', 'IN'), ('buses', 'NNS'), ('and', 'CC'), ('planes', 'NNS'), ('go', 'VBP'), ('high', 'JJ'), ('good', 'JJ'), ('place', 'NN'), ('and', 'CC'), ('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('eye', 'NN'), ('boggling', 'VBG'), ('thing', 'NN')])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Entity Extraction: Extract specific information or entities from the recognized text. You can define patterns or use regular expressions to identify relevant entities such as names, dates, locations, or numbers. These extracted entities can then be used as parameters for your SPARQL query or for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"1\": {\"name\": \"John\", \"age\": \"27\", \"sex\": \"Male\"}, \"2\": {\"name\": \"Marie\", \"age\": \"22\", \"sex\": \"Female\"}, \"3\": {\"name\": \"Luna\", \"age\": \"24\", \"sex\": \"Female\", \"married\": \"No\"}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Now you can use the json module's functions, for example:\n",
    "data = {1: {'name': 'John', 'age': '27', 'sex': 'Male'},\n",
    "          2: {'name': 'Marie', 'age': '22', 'sex': 'Female'},\n",
    "          3: {'name': 'Luna', 'age': '24', 'sex': 'Female', 'married': 'No'}}\n",
    "json_string = json.dumps(data)  # Convert Python dict to JSON string\n",
    "print(json_string)\n",
    "\n",
    "# Output: {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract dates using regular expressions\n",
    "date_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "dates = re.findall(date_pattern, recognized_text)\n",
    "\n",
    "# Extract names using a pattern\n",
    "name_pattern = r'My name is (\\w+)'\n",
    "match = re.search(name_pattern, recognized_text)\n",
    "if match:\n",
    "    name = match.group(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Generation: Generate a SPARQL query based on the recognized text and the specific task or intent. You can use string manipulation techniques to construct a valid SPARQL query, incorporating the extracted entities or applying predefined templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a SPARQL query using recognized entities\n",
    "def generate_sparql_query(intent, entities):\n",
    "    if intent == \"find\":\n",
    "        # Query template for finding information\n",
    "        entity = None\n",
    "        for ent_text, ent_type in entities:\n",
    "            if ent_type == \"PERSON\" or ent_type == \"ORG\":\n",
    "                entity = ent_text\n",
    "                break\n",
    "        if entity:\n",
    "            sparql_query = f\"SELECT ?property ?value WHERE {{ <{entity}> ?property ?value }}\"\n",
    "        else:\n",
    "            sparql_query = \"No entity found for the query.\"\n",
    "    elif intent == \"count\":\n",
    "        # Query template for counting entities\n",
    "        entity_type = None\n",
    "        for ent_text, ent_type in entities:\n",
    "            if ent_type == \"PERSON\" or ent_type == \"ORG\":\n",
    "                entity_type = ent_type.lower()\n",
    "                break\n",
    "        if entity_type:\n",
    "            sparql_query = f\"SELECT (COUNT(?entity) AS ?count) WHERE {{ ?entity rdf:type dbpedia:{entity_type} }}\"\n",
    "        else:\n",
    "            sparql_query = \"No entity type found for the query.\"\n",
    "    else:\n",
    "        sparql_query = \"Intent not supported for the query.\"\n",
    "\n",
    "    return sparql_query\n",
    "\n",
    "# Call the function to generate the SPARQL query\n",
    "sparql_query = generate_sparql_query(intent, entities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT ?property ?value WHERE { <http://example.org/entity> ?property ?value }'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query a TTL (Turtle) file using SPARQL in Python, you can use the rdflib library, which provides support for working with RDF data. Here's an example of how to use SPARQL to query a TTL file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib.plugins.sparql import prepareQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the TTL file into an RDF graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "graph.parse(\"ttls/abacws_building-ontology-version-1.ttl\", format=\"turtle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your SPARQL query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = prepareQuery('''\n",
    "    SELECT ?subject ?predicate ?object\n",
    "    WHERE {\n",
    "        ?subject ?predicate ?object\n",
    "    }\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query selects all the triples in the TTL file.\n",
    "\n",
    "Execute the SPARQL query on the RDF graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "graph = Graph()\n",
    "graph.parse(\"ttls/abacws_building-ontology-version-1.ttl\", format=\"turtle\")\n",
    "\n",
    "query = prepareQuery('''\n",
    "    SELECT ?subject ?predicate ?object\n",
    "    WHERE {\n",
    "        ?subject ?predicate ?object\n",
    "    }\n",
    "''')\n",
    "\n",
    "results = graph.query(query)\n",
    "for row in results:\n",
    "    subject = row['subject']\n",
    "    predicate = row['predicate']\n",
    "    object = row['object']\n",
    "    print(f\"Subject: {subject}\")\n",
    "    print(f\"Predicate: {predicate}\")\n",
    "    print(f\"Object: {object}\")\n",
    "    print('---')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the query results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "graph = Graph()\n",
    "graph.parse(\"ttls/abacws_building-ontology-version-1.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = ('''SELECT ?subject ?predicate ?object\n",
    "    WHERE {\n",
    "        ?subject ?predicate ?object\n",
    "    }\n",
    "\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quryrunner(input):\n",
    "\n",
    "    query = prepareQuery(input)\n",
    "\n",
    "    results = graph.query(query)\n",
    "    for row in results:\n",
    "        subject = row['subject']\n",
    "        predicate = row['predicate']\n",
    "        object = row['object']\n",
    "        print(f\"Subject: {subject}\")\n",
    "        print(f\"Predicate: {predicate}\")\n",
    "        print(f\"Object: {object}\")\n",
    "        print('---')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quryrunner(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the subject, predicate, and object are extracted from each row of the query results, and they are printed out. You can customize the processing of the results based on your specific needs.\n",
    "\n",
    "That's it! You have successfully queried a TTL file using SPARQL in Python using the rdflib library. Remember to replace \"path/to/file.ttl\" with the actual path to your TTL file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "SELECT * WHERE {\n",
    "  ?sub ?pred ?obj .\n",
    "} LIMIT 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
